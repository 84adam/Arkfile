# Test App Plan: Build end-to-end functionality test scripts

`NOTE: This project likely to be halted where we are currently (working up through refresh token step) in favor of a purely Go-based functional testing framework; see: go-integration.md`

## Current Status

**FOUNDATION STATUS: ✅ COMPLETE AND VALIDATED**
- Static linking working correctly for ALL binaries (server + Go utilities)
- OPAQUE+TOTP authentication fully functional  
- Token refresh validation completely resolved
- All 10 test phases implemented so far are passing in test-app-curl.sh
- Admin authentication working with 6/6 tests passing in admin-auth-test.sh
- Go utility tools (arkfile-client, arkfile-admin)

**CRITICAL VALIDATION WORKFLOW:**
Always run this sequence after any substantial changes:
1. `sudo ./scripts/dev-reset.sh` (rebuild and redeploy)
2. `./scripts/testing/test-app-curl.sh` (validate 10+ phases pass)
3. `./scripts/testing/admin-auth-test.sh` (validate 6+ admin tests pass)

This workflow must never be broken - it ensures the foundation remains solid.

**GO UTILITIES STATUS:**
- ✅ arkfile-client: Fully implemented
- ✅ arkfile-admin: Fully implemented

## Introduction/Overview

The test-app.md project establishes a comprehensive end-to-end testing framework for the Arkfile secure file vault system by developing production-ready Go utilities that enable authentic user workflow validation through real server interactions. 

---

## PHASE 1 Overview

Phase 1 focuses on implementing the foundational components of the four-tool architecture to enable comprehensive file operations testing through authentic server interactions. The primary objective is to extend the existing `test-app-curl.sh` script with Go-based tools that perform real user workflows including OPAQUE authentication, large file encryption and upload, and file integrity verification, while establishing the architectural patterns that will support future administrative and testing capabilities.

The implementation centers on enhancing `cryptocli` with file generation and encryption capabilities that exactly replicate the cryptographic operations performed by the browser WASM client, ensuring that command-line encrypted files are fully compatible with the web interface through identical key derivation, encryption algorithms, and data formats. **Static linking ensures that cryptocli uses the identical libopaque implementation as the server and WASM client.** Simultaneously, `arkfile-client` will be enhanced to handle authenticated server communication including OPAQUE registration and login flows, TOTP setup and verification, session management with JWT tokens, and chunked file upload through real API endpoints **with support for both localhost and remote TLS 1.3 connections**. The integration between these tools follows a secure pattern where `arkfile-client` obtains authentication credentials and exports them to `cryptocli` for cryptographic operations, then uploads the resulting encrypted data through authenticated API calls.

The file operations testing workflow validates the complete user experience by first authenticating a test user through the OPAQUE protocol to obtain genuine export keys, generating a 100MB test file with deterministic content for integrity verification, encrypting the file using OPAQUE-derived keys through the same cryptographic functions as the web client, uploading the encrypted file via chunked upload API endpoints while maintaining session state, verifying the file appears correctly in the user's file listing with proper metadata, and confirming perfect file integrity through download and decryption workflows. This approach eliminates the need for mocking or simulation by performing authentic operations against the running server while maintaining the security boundaries established by the tool architecture.

The Phase 1 implementation integrates with the existing authentication testing in `test-app-curl.sh` by adding a new phase that leverages the authenticated session established by the current OPAQUE and TOTP flows. Rather than replacing the existing bash script authentication, the new Go tools extend the test suite by consuming the authentication tokens and session keys generated by the proven authentication workflow, ensuring compatibility with the current testing infrastructure while adding comprehensive file operations validation that exercises the complete encryption, upload, storage, and retrieval pipeline that forms the core value proposition of the Arkfile secure file vault system.

---

## PHASE 1 Implementation Details

Here's the expanded and revised outline with PHASE 1 split into three manageable sections:

## PHASE 1A: Basic Go Tools Foundation ✅ COMPLETED

### Implemented Components

#### 1. Core File Operations Utilities (`crypto/file_operations.go`)
**Status:** ✅ COMPLETED with comprehensive functionality

**Core Functions Implemented:**
- `GenerateTestFileContent(size, pattern)` - Creates deterministic test file content
- `GenerateTestFileToPath(path, size, pattern)` - Memory-efficient file generation directly to disk
- `CalculateFileHash(data)` / `CalculateFileHashFromPath(path)` - SHA-256 integrity verification
- `VerifyFileIntegrity(path, hash, size)` - Complete file integrity validation
- `ParseSizeString(str)` / `FormatFileSize(bytes)` - Human-readable size handling
- `CreateBasicEnvelope(keyType)` / `ParseBasicEnvelope(data)` - Basic encryption envelope headers

**File Patterns Supported:**
- **Sequential**: Bytes 0,1,2...255,0,1,2... (deterministic, ideal for testing)
- **Repeated**: Repeating seed text pattern (deterministic, recognizable)  
- **Random**: Cryptographically secure random data (non-deterministic)

**Technical Specifications:**
- Maximum file size: 2GB with 4MB chunked processing for memory efficiency
- SHA-256 hash verification for all integrity checking
- AES-256-GCM encryption with 32-byte keys, 12-byte nonces, 16-byte tags
- 2-byte envelope format: Version (0x01) + Key Type (account/custom/share/unknown)

#### 2. Enhanced cryptocli Commands (`cmd/cryptocli/commands/file_operations.go`)
**Status:** ✅ COMPLETED with full CLI functionality

**New Commands Implemented:**
```bash
# Generate test files with various sizes and patterns
cryptocli generate-test-file -size=100MB -pattern=sequential -output=test.dat

# Basic file encryption with static keys (testing only)
cryptocli encrypt-file-basic -input=test.dat -output=test.enc \
    -key-hex=0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef

# Basic file decryption with envelope parsing
cryptocli decrypt-file-basic -input=test.enc -output=decrypted.dat \
    -key-hex=0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef
```

**Command Features:**
- Full argument parsing with comprehensive help text
- Size specification with units (B, KB, MB, GB)
- Pattern selection and validation
- Optional hash file output for integrity verification
- Envelope header support with key type specification
- Comprehensive error handling and user feedback

#### 3. Comprehensive Testing Suite
**Status:** ✅ COMPLETED with 100% test success rate

**Unit Tests (`crypto/file_operations_test.go`):**
- File content generation with all patterns and sizes
- File-to-disk generation with integrity verification
- Hash calculation and verification accuracy
- Size string parsing and formatting
- File integrity verification workflows
- Envelope creation and parsing validation
- Error handling and edge cases
- Deterministic pattern consistency verification

**Integration Tests (`crypto/phase1a_integration_test.go`):**
- Complete file generation and verification workflow (9 size/pattern combinations)
- Basic encryption/decryption workflow validation
- Envelope creation and parsing for all key types
- Complete file encryption with envelope workflow
- Size string parsing validation
- Performance testing (10MB file generation, 1MB encryption)

**Test Results:**
```
=== All Tests PASSED ✅ ===
Unit Tests: 13 test groups covering all functions
Integration Tests: 6 comprehensive workflow scenarios  
Performance Tests: Large file handling validated
Overall: 100% success rate with 0 failures
```

### Usage Examples and Validation

#### File Generation:
```go
// Generate 1MB test file with sequential pattern
data, err := crypto.GenerateTestFileContent(1024*1024, crypto.PatternSequential)

// Generate file directly to disk (memory efficient)
hash, err := crypto.GenerateTestFileToPath("test.dat", 1024*1024, crypto.PatternRepeated)

// Verify file integrity
err := crypto.VerifyFileIntegrity("test.dat", expectedHash, expectedSize)
```

#### Basic Encryption:
```go
// Encrypt data with AES-256-GCM
key := make([]byte, 32) // Your 32-byte key
encrypted, err := crypto.EncryptGCM(data, key)
decrypted, err := crypto.DecryptGCM(encrypted, key)

// Create and parse envelopes
envelope := crypto.CreateBasicEnvelope("custom")
version, keyType, err := crypto.ParseBasicEnvelope(envelope)
```

### Architecture and Compatibility

**Dependencies:** No external dependencies - uses only Go standard library and static linking
**Integration:** Seamless compatibility with existing Arkfile codebase and static linking infrastructure
**Security:** Production-ready cryptographic operations with proper error handling
**Performance:** Memory-efficient processing supports multi-GB file operations
**Static Linking:** All binaries are self-contained with embedded libopaque libraries

### Files Created/Modified:
```
crypto/
├── file_operations.go          # Core utilities (NEW)
├── file_operations_test.go     # Comprehensive unit tests (NEW)
└── phase1a_integration_test.go # Integration & performance tests (NEW)

cmd/cryptocli/
├── main.go                     # Updated with new commands
└── commands/
    └── file_operations.go      # New cryptocli commands (NEW)
```

### Ready for PHASE 1B Integration

All tools use identical cryptographic implementations to the server. The authentication testing (test-app-curl.sh) successfully validates the complete OPAQUE+TOTP authentication flow, providing the perfect foundation for file operations integration.

**Next Steps:** PHASE 1B will integrate OPAQUE authentication with these foundational file operations, replacing static keys with OPAQUE-derived keys while maintaining full compatibility with the established architecture.

#### New arkfile-client Tool - Basic Structure
**Location:** `cmd/arkfile-client/main.go` (new tool)

```go
package main

import (
    "crypto/tls"
    "encoding/json"
    "fmt"
    "net/http"
    "os"
)

type ClientConfig struct {
    ServerURL   string `json:"server_url"`
    Username    string `json:"username"`
    TLSInsecure bool   `json:"tls_insecure"`
    TokenFile   string `json:"token_file"`
}

type AuthResponse struct {
    Token        string `json:"token"`
    RefreshToken string `json:"refreshToken"`
    SessionKey   string `json:"sessionKey"`
    ExportKey    string `json:"exportKey,omitempty"`
}

func main() {
    if len(os.Args) < 2 {
        printUsage()
        os.Exit(1)
    }
    
    switch os.Args[1] {
    case "health":
        healthCheck()
    case "login":
        loginUser()
    case "list-files":
        listFiles()
    case "status":
        showStatus()
    default:
        fmt.Printf("Unknown command: %s\n", os.Args[1])
        printUsage()
        os.Exit(1)
    }
}

func healthCheck() error {
    config := loadConfig()
    
    client := createHTTPClient(config)
    
    resp, err := client.Get(config.ServerURL + "/api/health")
    if err != nil {
        return fmt.Errorf("health check failed: %w", err)
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("health check returned status %d", resp.StatusCode)
    }
    
    fmt.Println("✅ Server health check passed")
    return nil
}

func loginUser() error {
    // Implementation for basic OPAQUE login flow
    // - Read username/password from flags or prompt
    // - Perform OPAQUE authentication
    // - Handle TOTP if required
    // - Store tokens to file
    // - Export session key for cryptocli usage
}

func listFiles() error {
    config := loadConfig()
    token := loadToken(config.TokenFile)
    
    client := createHTTPClient(config)
    
    req, err := http.NewRequest("GET", config.ServerURL+"/api/files", nil)
    if err != nil {
        return err
    }
    req.Header.Set("Authorization", "Bearer "+token)
    
    resp, err := client.Do(req)
    if err != nil {
        return fmt.Errorf("list files failed: %w", err)
    }
    defer resp.Body.Close()
    
    var result map[string]interface{}
    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return err
    }
    
    fmt.Printf("Files: %+v\n", result)
    return nil
}

func createHTTPClient(config *ClientConfig) *http.Client {
    transport := &http.Transport{
        TLSClientConfig: &tls.Config{
            InsecureSkipVerify: config.TLSInsecure,
        },
    }
    return &http.Client{Transport: transport}
}
```

### Testing and Validation

#### Basic Tool Testing
**Location:** `scripts/testing/test-go-tools-basic.sh` (new file)

```bash
#!/bin/bash
# Basic testing of Go tools without server integration

set -euo pipefail

echo "=== Testing cryptocli basic operations ==="

# Test file generation
echo "Testing file generation..."
./cryptocli generate-test-file \
    --size 10MB \
    --pattern sequential \
    --output /tmp/test-10mb.dat \
    --hash-output /tmp/test-10mb.hash

if [ -f "/tmp/test-10mb.dat" ] && [ -f "/tmp/test-10mb.hash" ]; then
    echo "✅ File generation successful"
    ls -lh /tmp/test-10mb.dat
    echo "Hash: $(cat /tmp/test-10mb.hash)"
else
    echo "❌ File generation failed"
    exit 1
fi

# Test basic encryption/decryption
echo "Testing basic encryption/decryption..."
TEST_KEY="0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"

./cryptocli encrypt-file-basic \
    --input /tmp/test-10mb.dat \
    --output /tmp/test-10mb.enc \
    --key-hex "$TEST_KEY"

./cryptocli decrypt-file-basic \
    --input /tmp/test-10mb.enc \
    --output /tmp/test-10mb-decrypted.dat \
    --key-hex "$TEST_KEY"

# Verify integrity
ORIGINAL_HASH=$(cat /tmp/test-10mb.hash)
DECRYPTED_HASH=$(sha256sum /tmp/test-10mb-decrypted.dat | cut -d' ' -f1)

if [ "$ORIGINAL_HASH" = "$DECRYPTED_HASH" ]; then
    echo "✅ Basic encryption/decryption cycle successful"
else
    echo "❌ Hash mismatch: $ORIGINAL_HASH != $DECRYPTED_HASH"
    exit 1
fi

# Test arkfile-client basic operations
echo "=== Testing arkfile-client basic operations ==="

# Test server health check (assuming server is running)
./arkfile-client health --server-url https://localhost:4443 --tls-insecure

echo "✅ All basic Go tool tests passed"

# Cleanup
rm -f /tmp/test-10mb.dat /tmp/test-10mb.hash /tmp/test-10mb.enc /tmp/test-10mb-decrypted.dat
```

## PHASE 1B: OPAQUE Integration and File Operations (BASH SCRIPT FOCUS)

**IMPLEMENTATION PRIORITY: Extending test-app-curl.sh with Phase 11 File Operations**

This phase focuses specifically on extending the existing `test-app-curl.sh` bash script with comprehensive file operations testing capabilities. The Go utilities (cryptocli and arkfile-client) will be enhanced to support the file operations workflow, but the primary deliverable is Phase 11 integration in the bash script that validates the complete file vault functionality.

**Key Implementation Strategy:**
- Build upon the successful 10-phase authentication testing in test-app-curl.sh (currently 100% passing)
- Add Phase 11 that leverages existing JWT tokens and session keys from authentication phases
- Use Go tools as the implementation mechanism for authentic file operations testing
- Future scope includes equivalent Go-based test scripts, but current focus is bash script extension

### Bash Script Integration: Phase 11 File Operations

#### Overview of Phase 11 Workflow
The new phase integrates seamlessly with the existing 10 authentication phases in `test-app-curl.sh`, using established session tokens and authenticated state to test core file vault functionality:

```bash
# Phase 11: File Operations Testing (Integration with test-app-curl.sh)
1. Generate deterministic test files (100MB with sequential pattern)
2. Build and verify Go tools (cryptocli + arkfile-client) 
3. Export authentication data from existing bash script session
4. Authenticate with arkfile-client to obtain OPAQUE export key
5. Encrypt files using authentic OPAQUE-derived keys via cryptocli
6. Upload encrypted files using chunked upload API via arkfile-client
7. Verify files in user's listing via authenticated API calls
8. Download files back through authenticated API endpoints
9. Decrypt downloaded files using cryptocli with OPAQUE keys
10. Verify perfect integrity through complete hash comparison
11. Clean up all test artifacts and temporary files
```

#### Required Go Tool Enhancements for Bash Script Integration

**cryptocli Extensions for test-app-curl.sh:**
```bash
# Commands needed by Phase 11 in the bash script:

# Generate deterministic test files
./cryptocli generate-test-file --size 100MB --pattern sequential --output test.dat --hash-output test.hash

# Encrypt with OPAQUE export key (obtained from arkfile-client authentication)
./cryptocli encrypt-chunked-opaque --input test.dat --output-dir chunks/ \
    --export-key $OPAQUE_EXPORT_KEY --username $TEST_USERNAME --file-id "test.dat"

# Decrypt downloaded files using OPAQUE keys
./cryptocli decrypt-file-opaque --input downloaded.enc --output decrypted.dat \
    --export-key $OPAQUE_EXPORT_KEY --username $TEST_USERNAME
```

**arkfile-client Extensions for test-app-curl.sh:**
```bash
# Commands needed by Phase 11 in the bash script:

# Authenticate and export OPAQUE key for bash script usage
./arkfile-client authenticate --config client_config.json \
    --export-opaque-key opaque_export_key.hex --reuse-session

# Upload encrypted file chunks
./arkfile-client upload --config client_config.json --manifest chunks.json \
    --chunks-dir chunks/ --filename "test.dat"

# List files to verify upload
./arkfile-client list-files --config client_config.json --output-json listing.json

# Download files for integrity verification
./arkfile-client download --file-id $FILE_ID --output downloaded.enc \
    --export-encrypted-fek fek.bin --config client_config.json
```

### Detailed bash Script Implementation Plan

#### Step 1: Phase 11 Integration Point
**Location:** `scripts/testing/test-app-curl.sh` (add after line ~1500)

```bash
# Add Phase 11 after existing Phase 10 (logout and cleanup)
phase_file_operations() {
    phase "FILE OPERATIONS WITH GO TOOLS"
    
    if [ ! -f "$TEMP_DIR/final_jwt_token" ] || [ ! -f "$TEMP_DIR/final_session_key" ]; then
        warning "No JWT token or session key available, skipping file operations tests"
        return
    fi
    
    # Build Go tools if needed
    build_go_tools
    
    # Export authentication data for Go tools
    export_auth_data_for_go_tools
    
    # Execute complete file operations workflow
    generate_test_file_with_cryptocli
    authenticate_with_client_tool
    encrypt_test_file_with_opaque
    upload_file_with_client
    verify_file_with_client
    download_and_decrypt_file
    verify_complete_integrity
    cleanup_file_operations_test
    
    success "File operations testing completed with Go tools"
}

# Call Phase 11 in main script flow
# Add after phase_logout_and_cleanup call:
phase_file_operations
```

#### Step 2: Go Tools Integration Functions
**Purpose:** Support functions for Phase 11 that handle Go tool building, authentication export, and workflow execution

```bash
build_go_tools() {
    log "Building Go tools if needed..."
    
    # Build cryptocli if not available or outdated
    if [ ! -x "./cryptocli" ] || [ "cmd/cryptocli" -nt "./cryptocli" ]; then
        log "Building cryptocli..."
        cd cmd/cryptocli && go build -o ../../cryptocli . && cd ../..
        success "cryptocli built successfully"
    fi
    
    # Build arkfile-client if not available or outdated  
    if [ ! -x "./arkfile-client" ] || [ "cmd/arkfile-client" -nt "./arkfile-client" ]; then
        log "Building arkfile-client..."
        cd cmd/arkfile-client && go build -o ../../arkfile-client . && cd ../..
        success "arkfile-client built successfully"
    fi
    
    # Verify tools work
    ./cryptocli --version >/dev/null 2>&1 || error "cryptocli build verification failed"
    ./arkfile-client --version >/dev/null 2>&1 || error "arkfile-client build verification failed"
    
    success "All Go tools built and verified"
}

export_auth_data_for_go_tools() {
    log "Exporting authentication data for Go tools..."
    
    local token session_key
    token=$(cat "$TEMP_DIR/final_jwt_token")
    session_key=$(cat "$TEMP_DIR/final_session_key")
    
    # Create secure temporary files for Go tool communication
    echo "$token" > "$TEMP_DIR/go_jwt_token"
    echo "$session_key" > "$TEMP_DIR/go_session_key"
    echo "$TEST_USERNAME" > "$TEMP_DIR/go_username"
    echo "$TEST_PASSWORD" > "$TEMP_DIR/go_password"
    
    # Set restrictive permissions
    chmod 600 "$TEMP_DIR/go_jwt_token" "$TEMP_DIR/go_session_key" "$TEMP_DIR/go_username" "$TEMP_DIR/go_password"
    
    success "Authentication data exported for Go tools"
}
```

#### Step 3: Core File Operations Workflow
**Purpose:** The actual file operations testing that validates complete file vault functionality

```bash
generate_test_file_with_cryptocli() {
    log "Generating 100MB test file with cryptocli..."
    
    local test_file="$TEMP_DIR/test-file-100mb.dat"
    local hash_file="$TEMP_DIR/test-file-100mb.hash"
    
    ./cryptocli generate-test-file \
        --size 100MB \
        --pattern sequential \
        --output "$test_file" \
        --hash-output "$hash_file" \
        --verify
    
    if [ -f "$test_file" ] && [ -f "$hash_file" ]; then
        local file_size
        file_size=$(stat -c%s "$test_file" 2>/dev/null || stat -f%z "$test_file" 2>/dev/null)
        local expected_size=$((100 * 1024 * 1024))
        
        if [ "$file_size" -eq "$expected_size" ]; then
            success "100MB test file generated successfully"
            info "File: $test_file ($(numfmt --to=iec $file_size))"
            info "SHA-256: $(cat "$hash_file")"
        else
            error "Generated file size mismatch: expected $expected_size, got $file_size"
        fi
    else
        error "Failed to generate test file or hash"
    fi
}

encrypt_test_file_with_opaque() {
    log "Encrypting test file with authentic OPAQUE export key..."
    
    local test_file="$TEMP_DIR/test-file-100mb.dat"
    local encrypted_dir="$TEMP_DIR/encrypted_chunks"
    local manifest_file="$TEMP_DIR/chunk_manifest.json"
    local export_key_file="$TEMP_DIR/opaque_export_key.hex"
    
    mkdir -p "$encrypted_dir"
    
    # Read export key obtained from arkfile-client authentication
    local export_key
    export_key=$(cat "$export_key_file")
    
    ./cryptocli encrypt-chunked-opaque \
        --input "$test_file" \
        --output-dir "$encrypted_dir" \
        --export-key "$export_key" \
        --username "$TEST_USERNAME" \
        --file-id "test-file-100mb.dat" \
        --key-type "account" \
        --manifest "$manifest_file"
    
    if [ -f "$manifest_file" ]; then
        local total_chunks
        total_chunks=$(jq -r '.totalChunks' "$manifest_file")
        success "File encrypted into $total_chunks chunks using authentic OPAQUE key"
        
        # Verify all chunks exist and are properly formatted
        local chunks_verified=0
        for ((i=0; i<total_chunks; i++)); do
            local chunk_file="$encrypted_dir/chunk_${i}.enc"
            if [ -f "$chunk_file" ]; then
                local chunk_size
                chunk_size=$(stat -c%s "$chunk_file" 2>/dev/null || stat -f%z "$chunk_file" 2>/dev/null)
                if [ "$chunk_size" -gt 28 ]; then  # nonce + tag minimum
                    chunks_verified=$((chunks_verified + 1))
                fi
            fi
        done
        
        if [ "$chunks_verified" -eq "$total_chunks" ]; then
            success "All $total_chunks encrypted chunks verified and properly formatted"
        else
            error "Chunk verification failed: verified $chunks_verified, expected $total_chunks"
        fi
    else
        error "Failed to encrypt test file into chunks"
    fi
}

verify_complete_integrity() {
    log "Verifying complete file integrity through entire workflow..."
    
    local original_hash decrypted_hash original_file decrypted_file
    original_file="$TEMP_DIR/test-file-100mb.dat"
    decrypted_file="$TEMP_DIR/final-decrypted-file.dat"
    
    original_hash=$(cat "$TEMP_DIR/test-file-100mb.hash")
    decrypted_hash=$(sha256sum "$decrypted_file" | cut -d' ' -f1)
    
    if [ "$original_hash" = "$decrypted_hash" ]; then
        success "🎉 PERFECT INTEGRITY VERIFIED - Complete workflow successful!"
        info "Original file →  Generate →  Encrypt →  Upload →  List →  Download →  Decrypt →  Verify"
        info "SHA-256 hashes:"
        info "  Original:  $original_hash"
        info "  Final:     $decrypted_hash"
        info "  ✅ EXACT MATCH - Zero data corruption through complete cycle"
        
        # Additional file size verification
        local original_size decrypted_size
        original_size=$(stat -c%s "$original_file" 2>/dev/null || stat -f%z "$original_file" 2>/dev/null)
        decrypted_size=$(stat -c%s "$decrypted_file" 2>/dev/null || stat -f%z "$decrypted_file" 2>/dev/null)
        
        if [ "$original_size" -eq "$decrypted_size" ]; then
            info "  File sizes: $(numfmt --to=iec $original_size) ✅ EXACT MATCH"
        else
            warning "File size mismatch: original=$original_size, decrypted=$decrypted_size"
        fi
        
    else
        error "INTEGRITY VERIFICATION FAILED - Hash mismatch detected!"
        error "Original:  $original_hash"
        error "Final:     $decrypted_hash"
        error "This indicates data corruption in the encryption/upload/download/decryption workflow"
    fi
}
```

### Success Criteria for Phase 11 Integration

**Phase 11 Success Metrics:**
- [ ] Generate 100MB deterministic test file successfully
- [ ] Build and verify Go tools (cryptocli + arkfile-client) automatically
- [ ] Export authentication data securely from existing bash script session
- [ ] Authenticate with arkfile-client and obtain authentic OPAQUE export key (64 bytes)
- [ ] Encrypt test file using OPAQUE-derived keys with proper envelope format
- [ ] Upload encrypted file chunks via authenticated API without errors
- [ ] Verify file appears correctly in authenticated user's file listing with proper metadata
- [ ] Download file successfully through authenticated API endpoints
- [ ] Decrypt downloaded file using authentic OPAQUE session keys
- [ ] Achieve 100% file integrity verification (perfect SHA-256 hash match)
- [ ] Clean up all test artifacts and temporary files properly
- [ ] Integrate seamlessly with existing 10-phase authentication workflow

**Integration Requirements:**
- Must not break existing 10 authentication phases (maintain 100% success rate)
- Must leverage existing JWT tokens and session keys from authentication phases
- Must build Go tools automatically if not present or outdated
- Must handle errors gracefully and provide detailed logging
- Must clean up all temporary files and sensitive data after completion
- Must provide comprehensive success/failure reporting

**Future Scope (Not Current Focus):**
- Equivalent Go-based test scripts that perform the same functions as test-app-curl.sh
- Native Go test frameworks that don't require bash script integration
- Advanced file operations testing (multiple file types, concurrent uploads, large file stress testing)

This approach ensures we extend the proven authentication foundation in test-app-curl.sh with comprehensive file operations testing while maintaining compatibility and reliability.

### Enhanced cryptocli with OPAQUE Support (Go Implementation Details)
**Location:** `cmd/cryptocli/commands/file_operations.go` (extend existing)

```go
func EncryptFileOPAQUE(args []string) error {
    fs := flag.NewFlagSet("encrypt-file-opaque", flag.ExitOnError)
    var (
        inputFile   = fs.String("input", "", "Input file path")
        outputFile  = fs.String("output", "", "Output file path")
        exportKey   = fs.String("export-key", "", "OPAQUE export key (hex)")
        username    = fs.String("username", "", "Username for key derivation")
        fileID      = fs.String("file-id", "", "File ID for key derivation")
        keyType     = fs.String("key-type", "account", "Key type: account or custom")
    )
    
    // Implementation:
    // 1. Parse and validate OPAQUE export key (64 bytes hex)
    // 2. Derive file encryption key using crypto.DeriveAccountFileKey
    // 3. Read input file
    // 4. Encrypt using derived key with crypto.EncryptGCM
    // 5. Create envelope with version and key type
    // 6. Write encrypted file with envelope
    // 7. Output file hash for verification
}

func EncryptChunkedOPAQUE(args []string) error {
    fs := flag.NewFlagSet("encrypt-chunked-opaque", flag.ExitOnError)
    var (
        inputFile  = fs.String("input", "", "Input file path")
        outputDir  = fs.String("output-dir", "", "Output directory for chunks")
        exportKey  = fs.String("export-key", "", "OPAQUE export key (hex)")
        username   = fs.String("username", "", "Username for key derivation")
        fileID     = fs.String("file-id", "", "File ID for key derivation")
        manifest   = fs.String("manifest", "", "Output manifest file")
        chunkSize  = fs.Int("chunk-size", 16*1024*1024, "Chunk size (default: 16MB)")
    )
    
    // Implementation:
    // 1. Derive file encryption key from OPAQUE export key
    // 2. Create envelope (2 bytes: version + key type)
    // 3. Split file into chunks of specified size
    // 4. For each chunk:
    //    - Generate unique 12-byte nonce
    //    - Encrypt with AES-GCM: nonce + encrypted_data + tag
    //    - Calculate SHA-256 of encrypted chunk
    //    - Write to chunk_N.enc file
    // 5. Create manifest JSON with envelope and chunk metadata
    // 6. Validate all chunks were created successfully
}

func DecryptFileOPAQUE(args []string) error {
    fs := flag.NewFlagSet("decrypt-file-opaque", flag.ExitOnError)
    var (
        inputFile    = fs.String("input", "", "Encrypted input file")
        outputFile   = fs.String("output", "", "Decrypted output file")
        exportKey    = fs.String("export-key", "", "OPAQUE export key (hex)")
        encryptedFEK = fs.String("encrypted-fek", "", "Encrypted FEK file")
        username     = fs.String("username", "", "Username for key derivation")
    )
    
    // Implementation:
    // 1. Parse OPAQUE export key
    // 2. If encrypted FEK provided, decrypt it with session key
    // 3. Otherwise derive file key from export key
    // 4. Parse envelope from encrypted file
    // 5. Decrypt file content using derived/decrypted key
    // 6. Write decrypted file
    // 7. Verify integrity if hash provided
}
```

#### Enhanced arkfile-client with Upload/Download
**Location:** `cmd/arkfile-client/main.go` (extend existing)

```go
func uploadFile() error {
    fs := flag.NewFlagSet("upload", flag.ExitOnError)
    var (
        manifest   = fs.String("manifest", "", "Chunk manifest file")
        chunksDir  = fs.String("chunks-dir", "", "Directory containing encrypted chunks")
        filename   = fs.String("filename", "", "Original filename")
        serverURL  = fs.String("server-url", "", "Server URL")
        tokenFile  = fs.String("token-file", "", "JWT token file")
        tlsInsecure = fs.Bool("tls-insecure", false, "Skip TLS verification")
    )
    
    // Implementation:
    // 1. Load JWT token from file
    // 2. Read manifest file with chunk metadata
    // 3. Initialize upload session via POST /api/uploads/init
    // 4. Upload each chunk via POST /api/uploads/{sessionId}/chunks/{chunkIndex}
    // 5. Complete upload via POST /api/uploads/{sessionId}/complete
    // 6. Verify upload success and get file ID
    // 7. Save upload response for verification
}

func downloadFile() error {
    fs := flag.NewFlagSet("download", flag.ExitOnError)
    var (
        fileID      = fs.String("file-id", "", "File ID to download")
        output      = fs.String("output", "", "Output file path")
        exportFEK   = fs.String("export-fek", "", "Export encrypted FEK to file")
        serverURL   = fs.String("server-url", "", "Server URL")
        tokenFile   = fs.String("token-file", "", "JWT token file")
        tlsInsecure = fs.Bool("tls-insecure", false, "Skip TLS verification")
    )
    
    // Implementation:
    // 1. Load JWT token from file
    // 2. Get file metadata via GET /api/files/{fileId}
    // 3. Download encrypted file via GET /api/files/{fileId}/download
    // 4. If export-fek specified, save encrypted FEK to file
    // 5. Save encrypted file to output path
    // 6. Return success with file metadata
}

func authenticateAndExportKey() error {
    // Enhanced authentication that captures and exports OPAQUE export key
    // 1. Perform OPAQUE login flow
    // 2. Handle TOTP authentication
    // 3. Capture export key during authentication process
    // 4. Store tokens and export key to files for cryptocli usage
    // 5. Create session file with all necessary authentication data
}
```

### Advanced Crypto Package Extensions
**Location:** `crypto/opaque_integration.go` (new file)

```go
package crypto

import (
    "crypto/rand"
    "encoding/hex"
    "fmt"
)

// ExportKeyData represents OPAQUE export key and derived session data
type ExportKeyData struct {
    ExportKey   []byte `json:"export_key"`
    SessionKey  []byte `json:"session_key"`
    Username    string `json:"username"`
}

// DeriveFileKeyFromExport derives file encryption key from OPAQUE export key
func DeriveFileKeyFromExport(exportKey []byte, username, fileID string) ([]byte, error) {
    if len(exportKey) != 64 {
        return nil, fmt.Errorf("export key must be 64 bytes, got %d", len(exportKey))
    }
    
    // Use existing key derivation function
    return DeriveAccountFileKey(exportKey, username, fileID)
}

// EncryptFileWithOPAQUE encrypts file using OPAQUE-derived key
func EncryptFileWithOPAQUE(data []byte, exportKey []byte, username, fileID string) ([]byte, error) {
    // Derive file encryption key
    fileKey, err := DeriveFileKeyFromExport(exportKey, username, fileID)
    if err != nil {
        return nil, fmt.Errorf("key derivation failed: %w", err)
    }
    
    // Encrypt file data
    encryptedData, err := EncryptGCM(data, fileKey)
    if err != nil {
        return nil, fmt.Errorf("encryption failed: %w", err)
    }
    
    // Create envelope
    envelope := CreateOPAQUEEnvelope("account")
    
    // Combine envelope + encrypted data
    result := make([]byte, len(envelope)+len(encryptedData))
    copy(result, envelope)
    copy(result[len(envelope):], encryptedData)
    
    return result, nil
}

// DecryptFileWithOPAQUE decrypts file using OPAQUE-derived key
func DecryptFileWithOPAQUE(encryptedData []byte, exportKey []byte, username, fileID string) ([]byte, error) {
    // Parse envelope (first 2 bytes)
    if len(encryptedData) < 2 {
        return nil, fmt.Errorf("encrypted data too short for envelope")
    }
    
    envelope := encryptedData[:2]
    ciphertext := encryptedData[2:]
    
    // Validate envelope
    if err := ValidateOPAQUEEnvelope(envelope); err != nil {
        return nil, fmt.Errorf("invalid envelope: %w", err)
    }
    
    // Derive file encryption key
    fileKey, err := DeriveFileKeyFromExport(exportKey, username, fileID)
    if err != nil {
        return nil, fmt.Errorf("key derivation failed: %w", err)
    }
    
    // Decrypt file data
    return DecryptGCM(ciphertext, fileKey)
}

// CreateChunkedEncryption encrypts file in chunks for upload
func CreateChunkedEncryption(data []byte, exportKey []byte, username, fileID string, chunkSize int) (*ChunkManifest, map[int][]byte, error) {
    // Derive file encryption key
    fileKey, err := DeriveFileKeyFromExport(exportKey, username, fileID)
    if err != nil {
        return nil, nil, err
    }
    
    // Create envelope
    envelope := CreateOPAQUEEnvelope("account")
    
    // Split into chunks and encrypt each
    chunks := make(map[int][]byte)
    var chunkInfos []ChunkInfo
    
    for i := 0; i < len(data); i += chunkSize {
        end := i + chunkSize
        if end > len(data) {
            end = len(data)
        }
        
        chunkData := data[i:end]
        chunkIndex := i / chunkSize
        
        // Generate unique nonce for this chunk
        nonce := make([]byte, 12)
        if _, err := rand.Read(nonce); err != nil {
            return nil, nil, fmt.Errorf("nonce generation failed: %w", err)
        }
        
        // Encrypt chunk with nonce
        encryptedChunk, err := EncryptChunkWithNonce(chunkData, fileKey, nonce)
        if err != nil {
            return nil, nil, fmt.Errorf("chunk encryption failed: %w", err)
        }
        
        chunks[chunkIndex] = encryptedChunk
        
        // Calculate chunk hash
        chunkHash := CalculateFileHash(encryptedChunk)
        
        chunkInfos = append(chunkInfos, ChunkInfo{
            Index: chunkIndex,
            File:  fmt.Sprintf("chunk_%d.enc", chunkIndex),
            Hash:  chunkHash,
            Size:  len(encryptedChunk),
        })
    }
    
    // Create manifest
    manifest := &ChunkManifest{
        Envelope:    hex.EncodeToString(envelope),
        TotalChunks: len(chunkInfos),
        ChunkSize:   chunkSize,
        Chunks:      chunkInfos,
    }
    
    return manifest, chunks, nil
}
```

### Testing Integration
**Location:** `scripts/testing/test-go-tools-opaque.sh` (new file)

```bash
#!/bin/bash
# Test OPAQUE integration with Go tools

set -euo pipefail

# Mock OPAQUE export key for testing (64 bytes hex)
MOCK_EXPORT_KEY="0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
TEST_USERNAME="test-user"
TEST_FILE_ID="test-file.dat"

echo "=== Testing OPAQUE integration ==="

# Generate test file
./cryptocli generate-test-file \
    --size 50MB \
    --pattern sequential \
    --output /tmp/test-50mb.dat \
    --hash-output /tmp/test-50mb.hash

echo "✅ Generated 50MB test file"

# Test OPAQUE encryption
./cryptocli encrypt-file-opaque \
    --input /tmp/test-50mb.dat \
    --output /tmp/test-50mb-opaque.enc \
    --export-key "$MOCK_EXPORT_KEY" \
    --username "$TEST_USERNAME" \
    --file-id "$TEST_FILE_ID"

echo "✅ OPAQUE encryption completed"

# Test OPAQUE decryption
./cryptocli decrypt-file-opaque \
    --input /tmp/test-50mb-opaque.enc \
    --output /tmp/test-50mb-opaque-decrypted.dat \
    --export-key "$MOCK_EXPORT_KEY" \
    --username "$TEST_USERNAME"

echo "✅ OPAQUE decryption completed"

# Verify integrity
ORIGINAL_HASH=$(cat /tmp/test-50mb.hash)
DECRYPTED_HASH=$(sha256sum /tmp/test-50mb-opaque-decrypted.dat | cut -d' ' -f1)

if [ "$ORIGINAL_HASH" = "$DECRYPTED_HASH" ]; then
    echo "✅ OPAQUE encryption/decryption integrity verified"
else
    echo "❌ Hash mismatch: $ORIGINAL_HASH != $DECRYPTED_HASH"
    exit 1
fi

# Test chunked encryption
./cryptocli encrypt-chunked-opaque \
    --input /tmp/test-50mb.dat \
    --output-dir /tmp/encrypted_chunks \
    --export-key "$MOCK_EXPORT_KEY" \
    --username "$TEST_USERNAME" \
    --file-id "$TEST_FILE_ID" \
    --manifest /tmp/chunk_manifest.json

echo "✅ Chunked encryption completed"

# Validate manifest and chunks
TOTAL_CHUNKS=$(jq -r '.totalChunks' /tmp/chunk_manifest.json)
echo "Generated $TOTAL_CHUNKS chunks"

for ((i=0; i<TOTAL_CHUNKS; i++)); do
    CHUNK_FILE="/tmp/encrypted_chunks/chunk_${i}.enc"
    if [ ! -f "$CHUNK_FILE" ]; then
        echo "❌ Missing chunk: $CHUNK_FILE"
        exit 1
    fi
done

echo "✅ All chunks validated"

# Cleanup
rm -rf /tmp/test-50mb* /tmp/encrypted_chunks /tmp/chunk_manifest.json

echo "✅ OPAQUE integration tests passed"
```

## PHASE 1C: Test Script Integration and Complete Workflow

### Integration with test-app-curl.sh
**Location:** `scripts/testing/test-app-curl.sh` (modifications)

```bash
# Add after existing authentication phases (around line 1500)

# PHASE 11: FILE OPERATIONS WITH GO TOOLS
phase_file_operations() {
    phase "FILE OPERATIONS WITH GO TOOLS"
    
    local timer_start
    [ "$PERFORMANCE_MODE" = true ] && timer_start=$(start_timer)
    
    if [ ! -f "$TEMP_DIR/final_jwt_token" ] || [ ! -f "$TEMP_DIR/final_session_key" ]; then
        warning "No JWT token or session key available, skipping file operations tests"
        return
    fi
    
    # Ensure Go tools are built
    build_go_tools
    
    # Export authentication data for Go tools
    export_auth_data_for_go_tools
    
    # Step 1: Generate test file
    generate_test_file_with_cryptocli
    
    # Step 2: Authenticate with arkfile-client to get OPAQUE export key
    authenticate_with_client_tool
    
    # Step 3: Encrypt file using authentic OPAQUE export key
    encrypt_test_file_with_opaque
    
    # Step 4: Upload encrypted file
    upload_file_with_client
    
    # Step 5: Verify file in listing
    verify_file_with_client
    
    # Step 6: Download and decrypt file
    download_and_decrypt_file
    
    # Step 7: Verify complete integrity
    verify_complete_integrity
    
    # Step 8: Cleanup
    cleanup_file_operations_test
    
    success "File operations testing completed with Go tools"
    
    if [ "$PERFORMANCE_MODE" = true ]; then
        local duration=$(end_timer "$timer_start")
        info "File operations completed in: $duration"
    fi
}

build_go_tools() {
    log "Building Go tools if needed..."
    
    # Build cryptocli if not available or outdated
    if [ ! -x "./cryptocli" ] || [ "cmd/cryptocli" -nt "./cryptocli" ]; then
        log "Building cryptocli..."
        cd cmd/cryptocli && go build -o ../../cryptocli . && cd ../..
        success "cryptocli built successfully"
    fi
    
    # Build arkfile-client if not available or outdated
    if [ ! -x "./arkfile-client" ] || [ "cmd/arkfile-client" -nt "./arkfile-client" ]; then
        log "Building arkfile-client..."
        cd cmd/arkfile-client && go build -o ../../arkfile-client . && cd ../..
        success "arkfile-client built successfully"
    fi
    
    # Verify tools work
    ./cryptocli --version >/dev/null 2>&1 || error "cryptocli build verification failed"
    ./arkfile-client --version >/dev/null 2>&1 || error "arkfile-client build verification failed"
    
    success "All Go tools built and verified"
}

export_auth_data_for_go_tools() {
    log "Exporting authentication data for Go tools..."
    
    local token session_key
    token=$(cat "$TEMP_DIR/final_jwt_token")
    session_key=$(cat "$TEMP_DIR/final_session_key")
    
    # Create secure temporary files for Go tool communication
    echo "$token" > "$TEMP_DIR/go_jwt_token"
    echo "$session_key" > "$TEMP_DIR/go_session_key"
    echo "$TEST_USERNAME" > "$TEMP_DIR/go_username"
    echo "$TEST_PASSWORD" > "$TEMP_DIR/go_password"
    
    # Set restrictive permissions
    chmod 600 "$TEMP_DIR/go_jwt_token" "$TEMP_DIR/go_session_key" "$TEMP_DIR/go_username" "$TEMP_DIR/go_password"
    
    success "Authentication data exported for Go tools"
}

generate_test_file_with_cryptocli() {
    log "Generating 100MB test file with cryptocli..."
    
    local test_file="$TEMP_DIR/test-file-100mb.dat"
    local hash_file="$TEMP_DIR/test-file-100mb.hash"
    
    ./cryptocli generate-test-file \
        --size 100MB \
        --pattern sequential \
        --output "$test_file" \
        --hash-output "$hash_file" \
        --verify
    
    if [ -f "$test_file" ] && [ -f "$hash_file" ]; then
        local file_size
        file_size=$(stat -c%s "$test_file" 2>/dev/null || stat -f%z "$test_file" 2>/dev/null)
        local expected_size=$((100 * 1024 * 1024))
        
        if [ "$file_size" -eq "$expected_size" ]; then
            success "100MB test file generated successfully"
            info "File: $test_file ($(numfmt --to=iec $file_size))"
            info "SHA-256: $(cat "$hash_file")"
        else
            error "Generated file size mismatch: expected $expected_size, got $file_size"
        fi
    else
        error "Failed to generate test file or hash"
    fi
}

authenticate_with_client_tool() {
    log "Authenticating with arkfile-client to obtain OPAQUE export key..."
    
    # Create client config
    cat > "$TEMP_DIR/client_config.json" <<EOF
{
    "server_url": "$ARKFILE_BASE_URL",
    "username": "$TEST_USERNAME",
    "tls_insecure": true,
    "token_file": "$TEMP_DIR/go_jwt_token",
    "session_file": "$TEMP_DIR/client_session.json"
}
EOF
    
    # Authenticate and export OPAQUE key
    ./arkfile-client authenticate \
        --config "$TEMP_DIR/client_config.json" \
        --password-file "$TEMP_DIR/go_password" \
        --export-opaque-key "$TEMP_DIR/opaque_export_key.hex" \
        --reuse-session
    
    if [ -f "$TEMP_DIR/opaque_export_key.hex" ]; then
        local key_size
        key_size=$(wc -c < "$TEMP_DIR/opaque_export_key.hex")
        # OPAQUE export key should be 128 hex chars (64 bytes)
        if [ "$key_size" -eq 128 ]; then
            success "OPAQUE export key obtained (64 bytes)"
            debug "Export key: $(head -c 20 "$TEMP_DIR/opaque_export_key.hex")..."
        else
            error "Invalid OPAQUE export key size: expected 128 hex chars, got $key_size"
        fi
    else
        error "Failed to obtain OPAQUE export key"
    fi
}

encrypt_test_file_with_opaque() {
    log "Encrypting test file with authentic OPAQUE export key..."
    
    local test_file="$TEMP_DIR/test-file-100mb.dat"
    local encrypted_dir="$TEMP_DIR/encrypted_chunks"
    local manifest_file="$TEMP_DIR/chunk_manifest.json"
    local export_key_file="$TEMP_DIR/opaque_export_key.hex"
    
    mkdir -p "$encrypted_dir"
    
    # Read export key
    local export_key
    export_key=$(cat "$export_key_file")
    
    ./cryptocli encrypt-chunked-opaque \
        --input "$test_file" \
        --output-dir "$encrypted_dir" \
        --export-key "$export_key" \
        --username "$TEST_USERNAME" \
        --file-id "test-file-100mb.dat" \
        --key-type "account" \
        --manifest "$manifest_file"
    
    if [ -f "$manifest_file" ]; then
        local total_chunks
        total_chunks=$(jq -r '.totalChunks' "$manifest_file")
        success "File encrypted into $total_chunks chunks using authentic OPAQUE key"
        
        # Verify all chunks exist and have correct format
        local chunks_verified=0
        for ((i=0; i<total_chunks; i++)); do
            local chunk_file="$encrypted_dir/chunk_${i}.enc"
            if [ -f "$chunk_file" ]; then
                # Verify chunk has minimum size (nonce + tag = 28 bytes minimum)
                local chunk_size
                chunk_size=$(stat -c%s "$chunk_file" 2>/dev/null || stat -f%z "$chunk_file" 2>/dev/null)
                if [ "$chunk_size" -gt 28 ]; then
                    chunks_verified=$((chunks_verified + 1))
                fi
            fi
        done
        
        if [ "$chunks_verified" -eq "$total_chunks" ]; then
            success "All $total_chunks encrypted chunks verified and properly formatted"
        else
            error "Chunk verification failed: verified $chunks_verified, expected $total_chunks"
        fi
    else
        error "Failed to encrypt test file into chunks"
    fi
}

upload_file_with_client() {
    log "Uploading encrypted file using arkfile-client..."
    
    local manifest_file="$TEMP_DIR/chunk_manifest.json"
    local encrypted_dir="$TEMP_DIR/encrypted_chunks"
    local config_file="$TEMP_DIR/client_config.json"
    
    ./arkfile-client upload \
        --config "$config_file" \
        --manifest "$manifest_file" \
        --chunks-dir "$encrypted_dir" \
        --filename "test-file-100mb.dat" \
        --progress
    
    if [ $? -eq 0 ]; then
        success "File uploaded successfully via arkfile-client"
        
        # Extract file ID from upload response
        if [ -f "$TEMP_DIR/upload_response.json" ]; then
            local file_id
            file_id=$(jq -r '.fileId' "$TEMP_DIR/upload_response.json")
            echo "$file_id" > "$TEMP_DIR/uploaded_file_id"
            info "File ID: $file_id"
        fi
    else
        error "File upload failed"
    fi
}

verify_file_with_client() {
    log "Verifying uploaded file appears in listing..."
    
    local config_file="$TEMP_DIR/client_config.json"
    
    ./arkfile-client list-files \
        --config "$config_file" \
        --output-json > "$TEMP_DIR/file_listing.json"
    
    if [ $? -eq 0 ]; then
        # Check if our test file is in the listing
        local test_file_found
        test_file_found=$(jq -r '.files[] | select(.filename == "test-file-100mb.dat") | .filename' "$TEMP_DIR/file_listing.json")
        
        if [ "$test_file_found" = "test-file-100mb.dat" ]; then
            success "Test file found in file listing"
            
            # Validate file metadata
            local file_size sha256sum password_type storage_total
            file_size=$(jq -r '.files[] | select(.filename == "test-file-100mb.dat") | .size_bytes' "$TEMP_DIR/file_listing.json")
            sha256sum=$(jq -r '.files[] | select(.filename == "test-file-100mb.dat") | .sha256sum' "$TEMP_DIR/file_listing.json")
            password_type=$(jq -r '.files[] | select(.filename == "test-file-100mb.dat") | .passwordType' "$TEMP_DIR/file_listing.json")
            storage_total=$(jq -r '.storage.total_bytes' "$TEMP_DIR/file_listing.json")
            
            local expected_size=$((100 * 1024 * 1024))
            local expected_hash
            expected_hash=$(cat "$TEMP_DIR/test-file-100mb.hash")
            
            if [ "$file_size" -eq "$expected_size" ] && [ "$sha256sum" = "$expected_hash" ] && [ "$password_type" = "account" ]; then
                success "File metadata validated:"
                info "  Size: $(numfmt --to=iec $file_size)"
                info "  Hash: $sha256sum"
                info "  Type: $password_type"
                info "  Storage total: $(numfmt --to=iec $storage_total)"
            else
                error "File metadata validation failed: size=$file_size, hash_match=$([[ "$sha256sum" = "$expected_hash" ]] && echo "true" || echo "false"), type=$password_type"
            fi
        else
            error "Test file not found in listing"
        fi
    else
        error "Failed to retrieve file listing"
    fi
}

download_and_decrypt_file() {
    log "Downloading and decrypting file to verify complete workflow..."
    
    local file_id
    file_id=$(cat "$TEMP_DIR/uploaded_file_id")
    local config_file="$TEMP_DIR/client_config.json"
    local download_path="$TEMP_DIR/downloaded-encrypted-file.dat"
    local fek_path="$TEMP_DIR/downloaded_encrypted_fek.bin"
    local decrypted_path="$TEMP_DIR/final-decrypted-file.dat"
    local export_key_file="$TEMP_DIR/opaque_export_key.hex"
    
    # Download encrypted file and FEK
    ./arkfile-client download \
        --config "$config_file" \
        --file-id "$file_id" \
        --output "$download_path" \
        --export-encrypted-fek "$fek_path"
    
    if [ $? -eq 0 ] && [ -f "$download_path" ] && [ -f "$fek_path" ]; then
        success "Encrypted file and FEK downloaded successfully"
        
        local download_size
        download_size=$(stat -c%s "$download_path" 2>/dev/null || stat -f%z "$download_path" 2>/dev/null)
        info "Downloaded encrypted file size: $(numfmt --to=iec $download_size)"
        
        # Decrypt file using cryptocli with OPAQUE export key
        local export_key
        export_key=$(cat "$export_key_file")
        
        ./cryptocli decrypt-file-opaque \
            --input "$download_path" \
            --output "$decrypted_path" \
            --export-key "$export_key" \
            --encrypted-fek "$fek_path" \
            --username "$TEST_USERNAME"
        
        if [ -f "$decrypted_path" ]; then
            success "File decryption completed using OPAQUE export key"
            
            local decrypted_size
            decrypted_size=$(stat -c%s "$decrypted_path" 2>/dev/null || stat -f%z "$decrypted_path" 2>/dev/null)
            info "Decrypted file size: $(numfmt --to=iec $decrypted_size)"
        else
            error "File decryption failed"
        fi
    else
        error "File download failed"
    fi
}

verify_complete_integrity() {
    log "Verifying complete file integrity through entire workflow..."
    
    local original_hash decrypted_hash original_file decrypted_file
    original_file="$TEMP_DIR/test-file-100mb.dat"
    decrypted_file="$TEMP_DIR/final-decrypted-file.dat"
    
    original_hash=$(cat "$TEMP_DIR/test-file-100mb.hash")
    decrypted_hash=$(sha256sum "$decrypted_file" | cut -d' ' -f1)
    
    if [ "$original_hash" = "$decrypted_hash" ]; then
        success "🎉 PERFECT INTEGRITY VERIFIED - Complete workflow successful!"
        info "Original file →  Generate →  Encrypt →  Upload →  List →  Download →  Decrypt →  Verify"
        info "SHA-256 hashes:"
        info "  Original:  $original_hash"
        info "  Final:     $decrypted_hash"
        info "  ✅ EXACT MATCH - Zero data corruption through complete cycle"
        
        # Additional file size verification
        local original_size decrypted_size
        original_size=$(stat -c%s "$original_file" 2>/dev/null || stat -f%z "$original_file" 2>/dev/null)
        decrypted_size=$(stat -c%s "$decrypted_file" 2>/dev/null || stat -f%z "$decrypted_file" 2>/dev/null)
        
        if [ "$original_size" -eq "$decrypted_size" ]; then
            info "  File sizes: $(numfmt --to=iec $original_size) ✅ EXACT MATCH"
        else
            warning "File size mismatch: original=$original_size, decrypted=$decrypted_size"
        fi
        
    else
        error "INTEGRITY VERIFICATION FAILED - Hash mismatch detected!"
        error "Original:  $original_hash"
        error "Final:     $decrypted_hash"
        error "This indicates data corruption in the encryption/upload/download/decryption workflow"
    fi
}

cleanup_file_operations_test() {
    log "Cleaning up file operations test files and data..."
    
    # Remove local test files
    rm -f "$TEMP_DIR/test-file-100mb.dat"
    rm -f "$TEMP_DIR/test-file-100mb.hash"
    rm -rf "$TEMP_DIR/encrypted_chunks"
    rm -f "$TEMP_DIR/chunk_manifest.json"
    rm -f "$TEMP_DIR/downloaded-encrypted-file.dat"
    rm -f "$TEMP_DIR/downloaded_encrypted_fek.bin"
    rm -f "$TEMP_DIR/final-decrypted-file.dat"
    rm -f "$TEMP_DIR/upload_response.json"
    rm -f "$TEMP_DIR/file_listing.json"
    rm -f "$TEMP_DIR/uploaded_file_id"
    
    # Clean up Go tool configuration and auth files
    rm -f "$TEMP_DIR/client_config.json"
    rm -f "$TEMP_DIR/client_session.json"
    rm -f "$TEMP_DIR/opaque_export_key.hex"
    rm -f "$TEMP_DIR/go_jwt_token"
    rm -f "$TEMP_DIR/go_session_key"
    rm -f "$TEMP_DIR/go_username"
    rm -f "$TEMP_DIR/go_password"
    
    success "File operations test cleanup completed"
    info "All temporary files and authentication data securely removed"
}
```

### Build System Integration
**Location:** Root `Makefile` (new/updated)

```makefile
# Go tools building
.PHONY: build-go-tools clean-go-tools test-go-tools

build-go-tools:
	@echo "Building Go tools..."
	cd cmd/cryptocli && go build -o ../../cryptocli .
	cd cmd/arkfile-client && go build -o ../../arkfile-client .
	@echo "✅ Go tools built successfully"

clean-go-tools:
	rm -f cryptocli arkfile-client
	@echo "✅ Go tools cleaned"

test-go-tools: build-go-tools
	@echo "Testing Go tools..."
	./scripts/testing/test-go-tools-basic.sh
	./scripts/testing/test-go-tools-opaque.sh
	@echo "✅ Go tools tests passed"

# Integration with existing test targets
test-complete: build-go-tools
	./scripts/testing/test-app-curl.sh

test-file-operations: build-go-tools
	./scripts/testing/test-app-curl.sh --phase file-operations

# Development targets
dev-test-files: build-go-tools
	./scripts/testing/test-app-curl.sh --phase file-operations --debug --skip-cleanup

# Dependencies
cmd/cryptocli/cryptocli: $(shell find cmd/cryptocli -name '*.go')
	cd cmd/cryptocli && go build -o cryptocli .

cmd/arkfile-client/arkfile-client: $(shell find cmd/arkfile-client -name '*.go')
	cd cmd/arkfile-client && go build -o arkfile-client .
```

---

`NOTE: FINISH PHASE 1 AND THEN REVISIT/REVISE PLAN FOR SUBSEQUENT PHASES BELOW`

---

## PHASE 2 OUTLINE: Anonymous File Sharing Operations

- **Share Creation**
  - Extend cryptocli with Argon2id share password key derivation
  - Add arkfile-client share creation and password setting commands
  - Implement FEK re-encryption for anonymous access

- **Anonymous Download Testing**
  - Test anonymous file access without authentication
  - Validate share password verification and decryption
  - Verify timing protection and rate limiting on share endpoints

- **Complete Sharing Workflow**
  - Add Phase 12 to test-app-curl.sh for share creation and access
  - Test: authenticate → upload → create share → logout → anonymous download
  - Verify file integrity through anonymous decryption cycle

---

## PHASE 3 OUTLINE: Complete System Validation

- **Single Comprehensive Test Script**
  - Combine all phases into one master validation script
  - Test complete user journey: register → login → upload → share → anonymous access
  - Include performance benchmarking and timing measurements

- **Error Handling and Edge Cases**
  - Test authentication failures, file corruption, network errors
  - Validate security boundaries and proper error responses
  - Test cleanup and recovery from partial failures
  
- **Production Readiness Validation**
  - Comprehensive integrity checking across all operations
  - Performance validation with large files and concurrent operations
  - Final verification that all core features work end-to-end

---
